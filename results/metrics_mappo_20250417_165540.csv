epoch,reward,policy_loss,value_loss,entropy_loss,total_loss,computation_cost,transmission_cost,delay_penalty,training_time,agent_type,params,inference_time,estimated_cost,steps_per_episode,n_agents,agent_0_policy_loss,agent_0_value_loss,agent_0_entropy_loss
3,-1.0794892950252166,0.0022562656085938215,6878.32373046875,0.693010687828064,6877.6329760465305,0.0,0.0,0.0,9.106383562088013,MAPPO,0,0,2.0833500000000003e-05,1000,1,0.0022562656085938215,6878.32373046875,0.693010687828064
4,-1.6708120153631807,0.002474976470693946,8525.896484375,0.6930559873580933,8525.205903364113,0.0,0.0,0.0,8.583024978637695,MAPPO,0,0,2.0833500000000003e-05,1000,1,0.002474976470693946,8525.896484375,0.6930559873580933
